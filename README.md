**Cloning the Repository**

```bash
git clone https://github.com/srira-amirishetty/gta_vi_landing_page_animation.git
cd news-extractor
```
Frontend Environment Variables

create .env file and paste

```bash
VITE_API_URL=http://localhost:3000
```

**Installation**

Frontend SetUp

```bash
cd frontend/frontend
npm install
npm run dev
```

Backend Setup

open new terminal and run 


Backend Environment Variables

create .env file and paste

```bash
JINA_API_KEY=your_jina_api_key
QDRANT_URL=your_qdrant_url
QDRANT_API_KEY=yout_qdrant_api_key
COLLECTION_NAME=news_articles
GEMINI_API_KEY=your_gemini_api_key
REDIS_URL=your_redis_url
PORT=3000
```

For Running Backend

 ```bash
npm install
nodemon index.js
```

For News Ingestion

open new terminal and run

 ```bash
node ingest.js
```


Below is a clean, professional GitHub README tailored for your assignment.
You can paste it directly into your projectâ€™s README.md.

It clearly explains:

âœ” Tech stack
âœ” RAG pipeline
âœ” Backend
âœ” Frontend
âœ” Redis (1-hour TTL)
âœ” Qdrant
âœ” Gemini LLM
âœ” Streaming responses
âœ” Setup steps
âœ” API endpoints
âœ” Folder structure
âœ” Screenshots placeholders
âœ” Everything required for a Full-Stack Developer assignment at Voosh

ğŸ“„ README.md
ğŸš€ RAG-Powered News Chatbot

A full-stack Retrieval-Augmented Generation (RAG) chatbot that answers questions over a news corpus.
Built as part of a Full-Stack Developer assignment.

This system ingests ~50+ news articles, embeds them, stores them in a vector database, retrieves relevant chunks using semantic search, and then generates an answer using Gemini 1.5 Flash with RAG-context injection.

ğŸ§  Tech Stack
ğŸ”¹ Backend (Node.js + Express)

Node.js + Express â€” REST API for chat, sessions, streaming

Gemini 1.5 Flash (Google API) â€” final answer generation (LLM)

Jina Embeddings v3 â€” high-quality free-tier embeddings (1024 dimensions)

Qdrant Vector Database â€” semantic search for article chunks

Redis (Upstash or Local Redis)

stores per-session chat history

TTL = 1 hour

resets session on demand

Streaming (SSE) â€” real-time token-level responses like ChatGPT

ğŸ”¹ Frontend (React + SCSS)

React + Vite

Chat UI with message bubbles

Streaming typing animation

Reset conversation button

Persistent session (stored in localStorage)

ğŸ”¹ Deployment Ready

Works with Render / Railway / Vercel

Suitable for production use with small modifications

ğŸ” System Architecture
User â†’ React Frontend â†’ Express Backend â†’ Redis (session storage)
                                      â†’ Qdrant (vector search)
                                      â†’ Jina (embeddings)
                                      â†’ Gemini (LLM)

ğŸ“Œ Features
âœ… 1. RAG Pipeline

Ingests ~50 news articles

Splits into 500â€“800 character chunks

Generates embeddings via Jina v3

Stores vectors + payload in Qdrant

Retrieves top-k relevant chunks

Sends them to Gemini for grounded answers

âœ… 2. Session-Based Chat

Each new user â†’ new session ID

Chat stored in Redis

TTL = 1 hour

Session reset clears only that sessionâ€™s history

âœ… 3. Gemini-Powered Answering

Uses generateContentStream() for streaming

RAG ensures answers are article-grounded, non-hallucinatory

âœ… 4. Frontend Chat UI

Bubbles for user & assistant

Auto-scroll

Streaming token-by-token output

Reset button

History loaded on page refresh
